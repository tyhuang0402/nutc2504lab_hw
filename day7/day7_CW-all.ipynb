{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1549db1e",
   "metadata": {},
   "source": [
    "# Day. 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa05d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e411d9",
   "metadata": {},
   "source": [
    "## CW - 05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c024d",
   "metadata": {},
   "source": [
    "### pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf77535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking PDF: ./CW/05/example.pdf\n",
      "Total pages: 3\n",
      "\n",
      "Page no. 1 has text layer (979 characters)\n",
      "Page no. 2 has text layer (383 characters)\n",
      "Page no. 3 has text layer (1440 characters)\n",
      "\n",
      "==================================================\n",
      "Check results:\n",
      "- Page with text layer count: 3/3\n",
      "- Coverage rate: 100.00%\n",
      "- Total characters: 2802\n",
      "-Conclusion: This pdf has text layer and can be extract directly.\n",
      "Markdown file exported to: ./CW/05/example_extracted-pdfplumber.md\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "def check_pdf_text_layer(pdf_path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            total_pages = len(pdf.pages)\n",
    "            pages_w_text = 0\n",
    "            total_chrs = 0\n",
    "\n",
    "            print(f\"Checking PDF: {pdf_path}\")\n",
    "            print(f\"Total pages: {total_pages}\\n\")\n",
    "\n",
    "            for i, page in enumerate(pdf.pages, 1):\n",
    "                text = page.extract_text()\n",
    "\n",
    "                if text and text.strip():\n",
    "                    pages_w_text += 1\n",
    "                    char_count = len(text.strip())\n",
    "                    total_chrs += char_count\n",
    "                    print(f\"Page no. {i} has text layer ({char_count} characters)\")\n",
    "                else:\n",
    "                    print(f\"Page no. {i} has no text layer or is blank.\")\n",
    "\n",
    "            has_text_layer = pages_w_text > 0\n",
    "            coverage_rate = (pages_w_text / total_pages * 100) if total_pages > 0 else 0\n",
    "\n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Check results:\")\n",
    "            print(f\"- Page with text layer count: {pages_w_text}/{total_pages}\")\n",
    "            print(f\"- Coverage rate: {coverage_rate:.2f}%\")\n",
    "            print(f\"- Total characters: {total_chrs}\")\n",
    "            print(f\"-Conclusion: {'This pdf has text layer and can be extract directly.' if has_text_layer else 'This pdf has no extractable text layer.'}\")\n",
    "\n",
    "            output_path = os.path.splitext(pdf_path)[0] + \"_extracted-pdfplumber.md\"\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "            print(f\"Markdown file exported to: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERR: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"./CW/05/example.pdf\"\n",
    "    result = check_pdf_text_layer(pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae082a",
   "metadata": {},
   "source": [
    "### Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "def check_pdf_text_layer(pdf_path):\n",
    "    try:\n",
    "        # Initialize Docling converter\n",
    "        converter = DocumentConverter()\n",
    "        \n",
    "        print(f\"Checking PDF: {pdf_path}\")\n",
    "        print(\"Converting document with Docling...\")\n",
    "        \n",
    "        # Convert the PDF\n",
    "        result = converter.convert(pdf_path)\n",
    "        \n",
    "        # Export to markdown\n",
    "        markdown_text = result.document.export_to_markdown()\n",
    "        \n",
    "        if markdown_text and markdown_text.strip():\n",
    "            total_chars = len(markdown_text.strip())\n",
    "            \n",
    "            print(f\"Document successfully converted to markdown\")\n",
    "            print(f\"Total characters extracted: {total_chars}\")\n",
    "            \n",
    "            # Export to .md file\n",
    "            output_path = os.path.splitext(pdf_path)[0] + \"_extracted-docling.md\"\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(markdown_text)\n",
    "            \n",
    "            print(f\"Markdown file exported to: {output_path}\")\n",
    "            \n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Check results:\")\n",
    "            print(f\"- Total characters: {total_chars}\")\n",
    "            print(f\"- Conclusion: This PDF has text layer and can be extracted directly.\")\n",
    "            \n",
    "            return output_path\n",
    "        else:\n",
    "            print(f\"No text content extracted from the document.\")\n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Check results:\")\n",
    "            print(f\"- Total characters: 0\")\n",
    "            print(f\"- Conclusion: This PDF has no extractable text layer.\")\n",
    "            \n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERR: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"./CW/05/example.pdf\"\n",
    "    result = check_pdf_text_layer(pdf_file)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\nSuccess! Extracted text saved to: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efaa23",
   "metadata": {},
   "source": [
    "### Markitdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c692e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking PDF: ./CW/05/example.pdf\n",
      "Document successfully converted to markdown\n",
      "Total characters extracted: 2946\n",
      "Estimated pages (based on character count): 1\n",
      "Markdown file exported to: ./CW/05/example_extracted-markitdown.md\n",
      "\n",
      "==================================================\n",
      "Check results:\n",
      "- Total characters: 2946\n",
      "- Conclusion: This PDF has text layer and can be extracted directly.\n",
      "\n",
      "Success! Extracted text saved to: ./CW/05/example_extracted-markitdown.md\n"
     ]
    }
   ],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "def check_pdf_text_layer(pdf_path):\n",
    "    try:\n",
    "        md = MarkItDown()\n",
    "        result = md.convert(pdf_path)\n",
    "        \n",
    "        # MarkItDown returns the entire document as markdown text\n",
    "        text = result.text_content if hasattr(result, 'text_content') else result\n",
    "        \n",
    "        print(f\"Checking PDF: {pdf_path}\")\n",
    "        \n",
    "        # MarkItDown doesn't provide per-page analysis, so we extract overall statistics\n",
    "        if text and text.strip():\n",
    "            total_chars = len(text.strip())\n",
    "            # Rough estimation of pages based on character count (assuming ~2000 chars per page)\n",
    "            estimated_pages = max(1, total_chars // 2000)\n",
    "            \n",
    "            print(f\"Document successfully converted to markdown\")\n",
    "            print(f\"Total characters extracted: {total_chars}\")\n",
    "            print(f\"Estimated pages (based on character count): {estimated_pages}\")\n",
    "            \n",
    "            # Export to .md file\n",
    "            output_path = os.path.splitext(pdf_path)[0] + \"_extracted-markitdown.md\"\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "            \n",
    "            print(f\"Markdown file exported to: {output_path}\")\n",
    "            \n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Check results:\")\n",
    "            print(f\"- Total characters: {total_chars}\")\n",
    "            print(f\"- Conclusion: This PDF has text layer and can be extracted directly.\")\n",
    "            \n",
    "            return output_path\n",
    "        else:\n",
    "            print(f\"No text content extracted from the document.\")\n",
    "            print(f\"\\n{'=' * 50}\")\n",
    "            print(f\"Check results:\")\n",
    "            print(f\"- Total characters: 0\")\n",
    "            print(f\"- Conclusion: This PDF has no extractable text layer.\")\n",
    "            \n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERR: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"./CW/05/example.pdf\"\n",
    "    result = check_pdf_text_layer(pdf_file)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\nSuccess! Extracted text saved to: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a50861",
   "metadata": {},
   "source": [
    "## CW 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da7d74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:11,335 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:11,405 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:11,406 [RapidOCR] main.py:53: Using C:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:11,836 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:11,886 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:11,892 [RapidOCR] main.py:53: Using C:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:12,180 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:12,285 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 13:41:12,287 [RapidOCR] main.py:53: Using C:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, ApiVlmOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "\n",
    "pdf_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    ")\n",
    "\n",
    "\n",
    "# 建立文件轉換器\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 轉換 PDF 文件\n",
    "result = doc_converter.convert(\"./CW/06/sample_table.pdf\")\n",
    "\n",
    "# print(result)\n",
    "# 輸出為 Markdown 格式\n",
    "a = result.document.export_to_markdown()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2452301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error calling the API. Response was {\"detail\":\"Not Found\"}\n",
      "Error, could not process request: 4 validation errors for OpenAiApiResponse\n",
      "id\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "choices\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "created\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "usage\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "Error calling the API. Response was {\"detail\":\"Not Found\"}\n",
      "Error, could not process request: 4 validation errors for OpenAiApiResponse\n",
      "id\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "choices\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "created\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "usage\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "Error calling the API. Response was {\"detail\":\"Not Found\"}\n",
      "Error, could not process request: 4 validation errors for OpenAiApiResponse\n",
      "id\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "choices\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "created\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "usage\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "Error calling the API. Response was {\"detail\":\"Not Found\"}\n",
      "Error, could not process request: 4 validation errors for OpenAiApiResponse\n",
      "id\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "choices\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "created\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "usage\n",
      "  Field required [type=missing, input_value={'detail': 'Not Found'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# 建立文件轉換器\u001b[39;00m\n\u001b[32m     52\u001b[39m doc_converter = DocumentConverter(\n\u001b[32m     53\u001b[39m     format_options={\n\u001b[32m     54\u001b[39m         InputFormat.PDF: PdfFormatOption(\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     }\n\u001b[32m     59\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m hello = \u001b[43mdoc_converter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./HW/1.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(hello)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\document_converter.py:325\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Convert one document fetched from a file path, URL, or DocumentStream.\u001b[39;00m\n\u001b[32m    294\u001b[39m \n\u001b[32m    295\u001b[39m \u001b[33;03mNote: If the document content is given as a string (Markdown or HTML\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    315\u001b[39m \u001b[33;03m    ConversionError: An error occurred during conversion.\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    317\u001b[39m all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    318\u001b[39m     source=[source],\n\u001b[32m    319\u001b[39m     raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     page_range=page_range,\n\u001b[32m    324\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\document_converter.py:368\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    365\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    367\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\document_converter.py:467\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    465\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m item\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\document_converter.py:514\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    510\u001b[39m valid = (\n\u001b[32m    511\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    512\u001b[39m )\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    516\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\document_converter.py:537\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    535\u001b[39m pipeline = \u001b[38;5;28mself\u001b[39m._get_pipeline(in_doc.format)\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     conv_res = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:75\u001b[39m, in \u001b[36mBasePipeline.execute\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m TimeRecorder(\n\u001b[32m     71\u001b[39m         conv_res, \u001b[33m\"\u001b[39m\u001b[33mpipeline_total\u001b[39m\u001b[33m\"\u001b[39m, scope=ProfilingScope.DOCUMENT\n\u001b[32m     72\u001b[39m     ):\n\u001b[32m     73\u001b[39m         \u001b[38;5;66;03m# These steps are building and assembling the structure of the\u001b[39;00m\n\u001b[32m     74\u001b[39m         \u001b[38;5;66;03m# output DoclingDocument.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m         conv_res = \u001b[38;5;28mself\u001b[39m._assemble_document(conv_res)\n\u001b[32m     77\u001b[39m         \u001b[38;5;66;03m# From this stage, all operations should rely only on conv_res.output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:251\u001b[39m, in \u001b[36mPaginatedPipeline._build_document\u001b[39m\u001b[34m(self, conv_res)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# 2. Run pipeline stages\u001b[39;00m\n\u001b[32m    249\u001b[39m pipeline_pages = \u001b[38;5;28mself\u001b[39m._apply_on_pages(conv_res, init_pages)\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipeline_pages\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Must exhaust!\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Cleanup cached images\u001b[39;49;00m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_images\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_image_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:216\u001b[39m, in \u001b[36mPaginatedPipeline._apply_on_pages\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.build_pipe:\n\u001b[32m    214\u001b[39m     page_batch = model(conv_res, page_batch)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m page_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\models\\vlm_pipeline_models\\api_vlm_model.py:87\u001b[39m, in \u001b[36mApiVlmModel.__call__\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images:  \u001b[38;5;66;03m# Only if we have valid images\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m TimeRecorder(conv_res, \u001b[33m\"\u001b[39m\u001b[33mvlm_inference\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         predictions = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Attach results to pages\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m page, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pages_with_images, predictions):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Winter4T2H\\source\\repo\\nutc2504lab_hw\\.venv\\Lib\\site-packages\\docling\\models\\vlm_pipeline_models\\api_vlm_model.py:180\u001b[39m, in \u001b[36mApiVlmModel.process_images\u001b[39m\u001b[34m(self, image_batch, prompt)\u001b[39m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VlmPrediction(\n\u001b[32m    173\u001b[39m         text=page_tags,\n\u001b[32m    174\u001b[39m         num_tokens=num_tokens,\n\u001b[32m    175\u001b[39m         stop_reason=stop_reason,\n\u001b[32m    176\u001b[39m         input_prompt=input_prompt,\n\u001b[32m    177\u001b[39m     )\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=\u001b[38;5;28mself\u001b[39m.concurrency) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m executor.map(_process_single_image, \u001b[38;5;28mzip\u001b[39m(images, prompts))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "from docling.datamodel.pipeline_options_vlm_model import ApiVlmOptions, ResponseFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "\n",
    "\n",
    "def olmocr2_vlm_options(\n",
    "    model: str = \"allenai/olmOCR-2-7B-1025-FP8\",\n",
    "    hostname_and_port: str = \"https://ws-01.wade0426.me/v1/\",\n",
    "    prompt: str = \"Convert this page to markdown.\",\n",
    "    max_tokens: int = 4096,\n",
    "    temperature: float = 0.0,\n",
    "    api_key: str = \"\",) -> ApiVlmOptions:\n",
    "\n",
    "\n",
    "    headers = {}\n",
    "    if api_key:\n",
    "        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
    "   \n",
    "    options = ApiVlmOptions(\n",
    "        url=hostname_and_port,\n",
    "        params=dict(\n",
    "            model=model,\n",
    "            max_tokens=max_tokens,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        prompt=prompt,\n",
    "        timeout=120,  # olmocr2 可能需要較長處理時間\n",
    "        scale=2.0,  # 圖片縮放比例\n",
    "        temperature=temperature,\n",
    "        response_format=ResponseFormat.MARKDOWN,\n",
    "    )\n",
    "    return options\n",
    "\n",
    "# 配置 VLM pipeline 選項\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    enable_remote_services=True  # 必須啟用以呼叫遠端 API\n",
    ")\n",
    "\n",
    "# 設定 olmocr2 的 VLM 選項\n",
    "pipeline_options.vlm_options = olmocr2_vlm_options(\n",
    "    # model=model_name,\n",
    "    # hostname_and_port=vllm_hostname,\n",
    "    prompt=\"Convert this page to clean, readable markdown format.\",\n",
    "    temperature=0.0,  # olmocr2 建議使用較低的溫度\n",
    ")\n",
    "\n",
    "# 建立文件轉換器\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "            pipeline_cls=VlmPipeline,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "hello = doc_converter.convert(source=\"./HW/1.pdf\")\n",
    "print(hello)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
